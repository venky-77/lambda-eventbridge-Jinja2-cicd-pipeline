AWSTemplateFormatVersion: '2010-09-09'
Description: Lambda + EventBridge for Unload Redshift to S3 {{ table_name }} data.

Resources:
  LambdaEventBridge{{ schema_name | replace("_", "") }}{{ table_name | replace("_", "") }}:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: Lambda-eventbridge-cft-{{ schema_name }}-{{ table_name }}
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: arn:aws:iam::794038240530:role/lambda-role
      Timeout: 300
      MemorySize: 256
      Code:
        ZipFile: |
          import boto3
          import os
          import time
          import csv
          import io
          from datetime import datetime, timezone

          def lambda_handler(event, context):
              # Create Redshift client
              redshift = boto3.client('redshift-data', region_name='us-east-1')

              # Execute SQL query
              response = redshift.execute_statement(
                  WorkgroupName=os.environ['REDSHIFT_WORKGROUP'],
                  Database=os.environ['REDSHIFT_DATABASE'],
                  Sql=os.environ['SQL_QUERY'],
                  WithEvent=False
              )

              query_id = response['Id']

              # Wait for query to finish
              while True:
                  desc = redshift.describe_statement(Id=query_id)
                  if desc['Status'] in ['FINISHED', 'FAILED', 'ABORTED']:
                      break
                  time.sleep(1)

              if desc['Status'] != 'FINISHED':
                  raise Exception(f"Query failed: {desc.get('Error')}")

              # Get results
              result = redshift.get_statement_result(Id=query_id)

              # Convert records to CSV
              output = io.StringIO()
              writer = csv.writer(output)

              # Write header
              writer.writerow([col['name'] for col in result['ColumnMetadata']])

              # Write rows
              for record in result['Records']:
                  row = [list(field.values())[0] if field else None for field in record]
                  writer.writerow(row)

              # Generate dynamic timestamp for unique file
              timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
              s3_key = f"{os.environ['S3_KEY'].replace('.csv','')}_{timestamp}.csv"

              # Upload to S3
              s3 = boto3.client('s3')
              s3.put_object(
                  Bucket=os.environ['S3_BUCKET'],
                  Key=s3_key,
                  Body=output.getvalue()
              )

              return {
                  "statusCode": 200,
                  "body": f"Uploaded {len(result['Records'])} records to s3://{os.environ['S3_BUCKET']}/{s3_key}"
              }

      Environment:
        Variables:
          REDSHIFT_WORKGROUP: "{{ workgroup_name }}"
          REDSHIFT_DATABASE: "{{ Database_name }}"
          S3_BUCKET: "{{ s3_bucket_name }}"
          S3_KEY: "lambda/{{ schema_name }}_{{ table_name }}.csv"
          SQL_QUERY: "select * from {{ schema_name }}.{{ table_name }};"

  EventBridgeRule{{ schema_name | replace("_", "") }}{{ table_name | replace("_", "") }}:
    Type: AWS::Events::Rule
    Properties:
      Name: EB-Rule-{{ schema_name }}-{{ table_name }}
      ScheduleExpression: "{{ schedule_expression }}"
      State: ENABLED
      Targets:
        - Arn: !GetAtt LambdaEventBridge{{ schema_name | replace("_", "") }}{{ table_name | replace("_", "") }}.Arn
          Id: TargetLambda{{ schema_name | replace("_", "") }}{{ table_name | replace("_", "") }}

  LambdaInvokePermission{{ schema_name | replace("_", "") }}{{ table_name | replace("_", "") }}:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref LambdaEventBridge{{ schema_name | replace("_", "") }}{{ table_name | replace("_", "") }}
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt EventBridgeRule{{ schema_name | replace("_", "") }}{{ table_name | replace("_", "") }}.Arn
